from fastapi import HTTPException
from io import IOBase
from datetime import datetime, timedelta
import os
import httpx
from urllib.parse import urlparse
from typing import Any, List
from config import _config
from services.system.model import DecryptedImagePayload
import aiofiles
import json
import base64
import hashlib
from cryptography.hazmat.primitives.ciphers.aead import AESGCM
from cryptography.exceptions import InvalidTag
from pathlib import Path

BASE_DIR = Path(__file__).resolve().parent

CACHE_EXPIRE_HOURS = _config.get("CACHE_EXPIRE_HOURS")

CACHE_DIR = BASE_DIR / _config.get("CACHE_DIR")

os.makedirs(CACHE_DIR, exist_ok=True)


IMAGE_EXTENSIONS = (
    ".jpg",
    ".jpeg",
    ".png",
    ".webp",
    ".gif",
    ".bmp",
    ".avif",
)

IMAGE_KEYS = ("image", "Images", "img", "cover", "poster", "avatar", "thumb")

IMAGE_PATH_KEYWORDS = (
    "/images/",
    "/image/",
    "/art/",
    "/poster",
    "/thumb",
    "/backdrop",
    "/primary",
    "/logo",
)


def is_image_field(key: str) -> bool:
    return any(k in key.lower() for k in IMAGE_KEYS)


def next_monday_timestamp():
    today = datetime.now()
    days_ahead = 0 - today.weekday()
    if days_ahead <= 0:
        days_ahead += 7
    next_monday = today + timedelta(days=days_ahead)
    next_monday = next_monday.replace(hour=0, minute=0, second=0, microsecond=0)
    return int(next_monday.timestamp())


def _to_plain(value: Any) -> Any:
    """
    å°† ORM / Pydantic / dataclass è½¬ä¸º dict
    """
    # Pydantic v2
    if hasattr(value, "model_dump"):
        return value.model_dump()

    # Pydantic v1
    if hasattr(value, "dict"):
        return value.dict()

    # SQLAlchemy ORM
    if hasattr(value, "__dict__"):
        return {k: v for k, v in value.__dict__.items() if not k.startswith("_")}

    return value


def is_image_url(url: str) -> bool:
    parsed = urlparse(url)
    path = parsed.path.lower()

    # 1ï¸âƒ£ å¸¸è§„å›¾ç‰‡åŽç¼€
    if path.endswith(IMAGE_EXTENSIONS):
        return True

    # 2ï¸âƒ£ Emby / Jellyfin / Plex é£Žæ ¼
    if any(k in path for k in IMAGE_PATH_KEYWORDS):
        return True

    return False


def replace_domain_in_value(value: Any, exclude: List[str] = None) -> Any:
    """
    é€’å½’æ›¿æ¢ dict/list ä¸­çš„ã€å›¾ç‰‡ URLã€‘
    """

    prefix = _config.get("SYSTEM_IMAGE_PREFIX")

    if exclude is None:
        exclude = [
            "www.mgstage.com",
            "al.dmm.co.jp",
            "x.com",
            "www.instagram.com",
            "www.avbase.net",
            "ja.wikipedia.org",
            "www.tiktok.com",
        ]

    value = _to_plain(value)

    if isinstance(value, dict):
        result = {}
        for k, v in value.items():
            if isinstance(v, str) and is_image_field(k):
                result[k] = replace_domain_in_value(v, exclude)
            else:
                result[k] = replace_domain_in_value(v, exclude)
        return result

    elif isinstance(value, list):
        return [replace_domain_in_value(v, exclude) for v in value]

    elif isinstance(value, str):
        if value.startswith(("http://", "https://")):
            try:
                parsed = urlparse(value)

                # åŸŸåç™½åå•
                if parsed.netloc in exclude:
                    return value

                # ðŸš¨ åªæ›¿æ¢å›¾ç‰‡ URL
                if not is_image_url(value):
                    return value

                token = encrypt_payload(value)
                return f"{prefix}{token}"

            except Exception:
                return value

        return value


def get_cache_path(url: str) -> str:
    import hashlib

    hash_name = hashlib.md5(url.encode("utf-8")).hexdigest()
    return os.path.join(CACHE_DIR, f"{hash_name}")


async def fetch_and_cache_image(url: str) -> tuple[IOBase, dict]:
    cache_path = get_cache_path(url)

    if os.path.exists(cache_path):
        last_modified = datetime.fromtimestamp(os.path.getmtime(cache_path))
        if datetime.now() - last_modified < timedelta(hours=CACHE_EXPIRE_HOURS):
            etag = str(os.path.getmtime(cache_path))
            headers = {
                "Cache-Control": f"public, max-age={CACHE_EXPIRE_HOURS*3600}",
                "ETag": etag,
            }
            return open(cache_path, "rb"), headers
        else:
            os.remove(cache_path)

    os.makedirs(os.path.dirname(cache_path), exist_ok=True)

    async with httpx.AsyncClient() as client:
        resp = await client.get(url)
    if resp.status_code != 200:
        raise HTTPException(resp.status_code, "Failed to fetch image")

    async with aiofiles.open(cache_path, "wb") as f:
        await f.write(resp.content)

    etag = str(os.path.getmtime(cache_path))
    headers = {
        "Cache-Control": f"public, max-age={CACHE_EXPIRE_HOURS*3600}",
        "ETag": etag,
    }
    return open(cache_path, "rb"), headers


def encrypt_payload(url) -> str:
    """
    payload: DecryptedImagePayload å®žä¾‹
    è¿”å›žï¼šURL-safe base64 å­—ç¬¦ä¸²
    """
    payload = DecryptedImagePayload(url=url, exp=next_monday_timestamp())

    key = _config.get_image_token_key()
    aesgcm = AESGCM(key)

    plaintext = json.dumps(
        payload.model_dump(), separators=(",", ":"), ensure_ascii=False
    ).encode("utf-8")

    nonce = hashlib.sha256(plaintext).digest()[:12]

    ciphertext = aesgcm.encrypt(nonce, plaintext, None)
    token = base64.urlsafe_b64encode(nonce + ciphertext).decode("utf-8")
    return token


def decrypt_payload(token: str) -> DecryptedImagePayload:
    """
    è§£å¯† token å¹¶è¿”å›ž DecryptedImagePayload å®žä¾‹
    """
    try:
        raw = base64.urlsafe_b64decode(token.encode("utf-8"))
        nonce, ciphertext = raw[:12], raw[12:]
        key = _config.get_image_token_key()
        aesgcm = AESGCM(key)
        plaintext = aesgcm.decrypt(nonce, ciphertext, None)
        data = json.loads(plaintext.decode("utf-8"))
        payload = DecryptedImagePayload(**data)
        return payload
    except (InvalidTag, ValueError, json.JSONDecodeError) as e:
        raise ValueError("Invalid image token") from e
